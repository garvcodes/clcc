{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNV-Guided Contrastive Learning - Complete Pipeline\n",
    "\n",
    "This notebook walks through the entire pipeline from data loading to training and evaluation.\n",
    "\n",
    "## Steps:\n",
    "1. Data loading and preprocessing\n",
    "2. CNV inference (run separately in R)\n",
    "3. Dataset creation\n",
    "4. Model training\n",
    "5. Evaluation\n",
    "6. Downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import MultimodalEncoder, build_cnv_anchor_bank\n",
    "from losses import CombinedLoss\n",
    "from data_processing import MultimodalScDataset, preprocess_adata\n",
    "from train import train_model\n",
    "from evaluation import evaluate_alignment, plot_similarity_heatmap, plot_umap, plot_training_curves\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "First, you need to download the data from GEO (GSE131907).\n",
    "\n",
    "**Manual steps:**\n",
    "1. Go to: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE131907\n",
    "2. Download the count matrix for Patient P0006 (LUNG_T06 and LUNG_N06)\n",
    "3. Save to `data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we'll create synthetic data to test the pipeline\n",
    "# Replace this with actual data loading once you have the data\n",
    "\n",
    "def create_synthetic_data(n_cells=10000, n_genes=5884, n_subclusters=78):\n",
    "    \"\"\"Create synthetic data for testing.\"\"\"\n",
    "    print(\"Creating synthetic data...\")\n",
    "    \n",
    "    # Create expression matrix\n",
    "    X = np.random.negative_binomial(5, 0.3, (n_cells, n_genes)).astype(float)\n",
    "    \n",
    "    # Create obs with metadata\n",
    "    obs = pd.DataFrame({\n",
    "        'sample': np.random.choice(['LUNG_T06', 'LUNG_N06'], n_cells),\n",
    "        'cell_type': np.random.choice(['Epithelial', 'T cell', 'Myeloid'], n_cells),\n",
    "        'cancer_vs_normal': np.random.choice(['Cancer', 'Normal'], n_cells)\n",
    "    })\n",
    "    obs.index = [f'cell_{i}' for i in range(n_cells)]\n",
    "    \n",
    "    # Create var\n",
    "    var = pd.DataFrame(index=[f'gene_{i}' for i in range(n_genes)])\n",
    "    \n",
    "    # Create AnnData\n",
    "    adata = sc.AnnData(X=X, obs=obs, var=var)\n",
    "    \n",
    "    # Add CNV subclusters (would come from inferCNV)\n",
    "    adata.obs['subcluster'] = [f'cnv_cluster_{i % n_subclusters}' for i in range(n_cells)]\n",
    "    \n",
    "    # Create CNV profiles (would come from inferCNV)\n",
    "    cnv_profiles = pd.DataFrame(\n",
    "        np.random.randn(n_subclusters, n_genes),\n",
    "        index=[f'cnv_cluster_{i}' for i in range(n_subclusters)],\n",
    "        columns=var.index\n",
    "    )\n",
    "    \n",
    "    return adata, cnv_profiles\n",
    "\n",
    "# Create or load data\n",
    "adata, cnv_profiles = create_synthetic_data()\n",
    "\n",
    "print(f\"\\nData shape: {adata.shape}\")\n",
    "print(f\"CNV profiles shape: {cnv_profiles.shape}\")\n",
    "print(f\"Number of subclusters: {adata.obs['subcluster'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing\n",
    "\n",
    "Standard scRNA-seq preprocessing:\n",
    "- Filter cells and genes\n",
    "- Normalize\n",
    "- Log-transform\n",
    "- (Optional) Select highly variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "adata_processed = preprocess_adata(\n",
    "    adata.copy(),\n",
    "    min_genes=200,\n",
    "    min_cells=3,\n",
    "    target_sum=1e4,\n",
    "    n_top_genes=None,  # Keep all genes or set to 5884\n",
    "    log_transform=True\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed data shape: {adata_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: CNV Inference (Run in R)\n",
    "\n",
    "**This step must be done in R using inferCNV:**\n",
    "\n",
    "```R\n",
    "library(infercnv)\n",
    "\n",
    "# Create inferCNV object\n",
    "infercnv_obj = CreateInfercnvObject(\n",
    "    raw_counts_matrix=\"data/processed/counts_matrix.txt\",\n",
    "    annotations_file=\"data/processed/cell_annotations.txt\",\n",
    "    delim=\"\\t\",\n",
    "    gene_order_file=\"data/processed/gene_positions.txt\",\n",
    "    ref_group_names=c(\"Normal\")\n",
    ")\n",
    "\n",
    "# Run inferCNV\n",
    "infercnv_obj = infercnv::run(\n",
    "    infercnv_obj,\n",
    "    cutoff=0.1,\n",
    "    out_dir=\"data/processed/infercnv_output\",\n",
    "    cluster_by_groups=TRUE,\n",
    "    denoise=TRUE,\n",
    "    HMM=TRUE\n",
    ")\n",
    "```\n",
    "\n",
    "After running inferCNV:\n",
    "1. Load the subcluster assignments into `adata.obs['subcluster']`\n",
    "2. Load the CNV profiles matrix\n",
    "\n",
    "For this demo, we're using synthetic CNV data created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = MultimodalScDataset(\n",
    "    adata_processed,\n",
    "    cnv_profiles,\n",
    "    subcluster_col='subcluster',\n",
    "    expr_layer=None  # Use .X (log-normalized)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset size: {len(dataset)}\")\n",
    "\n",
    "# Test dataset\n",
    "sample = dataset[0]\n",
    "print(f\"Sample shapes:\")\n",
    "print(f\"  x_expr: {sample['x_expr'].shape}\")\n",
    "print(f\"  x_cnv: {sample['x_cnv'].shape}\")\n",
    "print(f\"  label: {sample['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of genes\n",
    "n_genes = adata_processed.n_vars\n",
    "\n",
    "# Initialize model\n",
    "model = MultimodalEncoder(\n",
    "    n_genes=n_genes,\n",
    "    hidden_dim=256,\n",
    "    latent_dim=64,\n",
    "    freeze_cnv=True\n",
    ")\n",
    "\n",
    "print(f\"Model initialized with {n_genes} genes\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Model\n",
    "\n",
    "**Note:** With synthetic data, we'll use fewer epochs for demo. \n",
    "With real data, use 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_epochs = 10  # Use 100 for real training\n",
    "batch_size = 512  # Use 4096 for real training (if GPU allows)\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Convert CNV profiles to tensor\n",
    "cnv_profiles_tensor = torch.FloatTensor(cnv_profiles.values)\n",
    "\n",
    "# Train\n",
    "model_trained, history = train_model(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    cnv_profiles_tensor=cnv_profiles_tensor,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    save_dir='../checkpoints',\n",
    "    save_every=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history, save_path='../figures/training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Alignment\n",
    "\n",
    "Compute top-k retrieval accuracy (target: 97.4% for k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = evaluate_alignment(\n",
    "    model=model_trained,\n",
    "    dataset=dataset,\n",
    "    cnv_profiles_tensor=cnv_profiles_tensor,\n",
    "    device=device,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"ALIGNMENT RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Z-space top-5 accuracy: {results['z_space_accuracy']:.1%}\")\n",
    "print(f\"H-space top-5 accuracy: {results['h_space_accuracy']:.1%}\")\n",
    "print(f\"\\nTarget z-space accuracy: 97.4%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CNV similarity heatmap\n",
    "plot_similarity_heatmap(\n",
    "    results['z_similarities'],\n",
    "    save_path='../figures/cnv_similarity_heatmap.png',\n",
    "    title=\"CNV Embeddings Similarity Matrix (Z-space)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP visualization colored by cancer vs normal\n",
    "cancer_labels = (adata_processed.obs['cancer_vs_normal'] == 'Cancer').astype(int).values\n",
    "\n",
    "umap_coords = plot_umap(\n",
    "    results['z_expr'],\n",
    "    cancer_labels,\n",
    "    color_by='Cancer (1) vs Normal (0)',\n",
    "    title=\"UMAP of Expression Embeddings\",\n",
    "    save_path='../figures/umap_cancer_vs_normal.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Store Embeddings in AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embeddings in adata for downstream analysis\n",
    "adata_processed.obsm['X_h_expr'] = results['h_expr']\n",
    "adata_processed.obsm['X_z_expr'] = results['z_expr']\n",
    "adata_processed.obsm['X_umap'] = umap_coords\n",
    "\n",
    "# Save\n",
    "adata_processed.write_h5ad('../data/processed/adata_with_embeddings.h5ad')\n",
    "print(\"Saved AnnData with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Downstream Analysis\n",
    "\n",
    "### Traditional Differential Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional DE: Cancer vs Normal in Epithelial cells\n",
    "epithelial_mask = adata_processed.obs['cell_type'] == 'Epithelial'\n",
    "adata_epithelial = adata_processed[epithelial_mask].copy()\n",
    "\n",
    "print(f\"Epithelial cells: {adata_epithelial.n_obs}\")\n",
    "\n",
    "# Run Wilcoxon test\n",
    "sc.tl.rank_genes_groups(\n",
    "    adata_epithelial,\n",
    "    groupby='cancer_vs_normal',\n",
    "    reference='Normal',\n",
    "    method='wilcoxon'\n",
    ")\n",
    "\n",
    "# Get top markers\n",
    "markers_df = sc.get.rank_genes_groups_df(adata_epithelial, group='Cancer')\n",
    "print(\"\\nTop 10 differentially expressed genes:\")\n",
    "print(markers_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNV-Conditioned Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use h-space embeddings for clustering\n",
    "sc.pp.neighbors(adata_processed, use_rep='X_h_expr', n_neighbors=30)\n",
    "sc.tl.leiden(adata_processed, resolution=0.5)\n",
    "\n",
    "print(f\"\\nFound {adata_processed.obs['leiden'].nunique()} Leiden clusters\")\n",
    "\n",
    "# Visualize clusters on UMAP\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Color by Leiden cluster\n",
    "scatter1 = axes[0].scatter(\n",
    "    umap_coords[:, 0],\n",
    "    umap_coords[:, 1],\n",
    "    c=adata_processed.obs['leiden'].astype(int),\n",
    "    cmap='tab20',\n",
    "    s=1,\n",
    "    alpha=0.6\n",
    ")\n",
    "axes[0].set_title('Leiden Clusters (CNV-informed)')\n",
    "plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "# Color by cancer vs normal\n",
    "scatter2 = axes[1].scatter(\n",
    "    umap_coords[:, 0],\n",
    "    umap_coords[:, 1],\n",
    "    c=cancer_labels,\n",
    "    cmap='RdBu_r',\n",
    "    s=1,\n",
    "    alpha=0.6\n",
    ")\n",
    "axes[1].set_title('Cancer vs Normal')\n",
    "plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/clustering_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **With Real Data:**\n",
    "   - Download GSE131907 Patient P0006\n",
    "   - Run inferCNV to get actual CNV profiles\n",
    "   - Train for 100 epochs with batch_size=4096\n",
    "   - Achieve 97.4% top-5 accuracy\n",
    "\n",
    "2. **CNV-Conditioned DE:**\n",
    "   - Identify neighborhoods with mixed cancer/normal cells\n",
    "   - Perform DE within CNV-consistent regions\n",
    "   - Compare to traditional DE results\n",
    "\n",
    "3. **Biomarker Validation:**\n",
    "   - Validate APOC1 downregulation\n",
    "   - Check other top markers (Table 1 in paper)\n",
    "   - Explore early malignant transition signatures\n",
    "\n",
    "4. **Multi-Patient Analysis:**\n",
    "   - Extend to other patients in GSE131907\n",
    "   - Assess reproducibility\n",
    "   - Study inter-patient variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the complete pipeline:\n",
    "\n",
    "✓ Data preprocessing  \n",
    "✓ Dataset creation  \n",
    "✓ Model training  \n",
    "✓ Evaluation (top-k retrieval)  \n",
    "✓ Visualization  \n",
    "✓ Downstream analysis  \n",
    "\n",
    "**Key files created:**\n",
    "- `model.py`: Encoder architectures\n",
    "- `losses.py`: Three loss functions\n",
    "- `data_processing.py`: Dataset utilities\n",
    "- `train.py`: Training loop\n",
    "- `evaluation.py`: Metrics and visualization\n",
    "\n",
    "**Next:** Run with real data to reproduce the paper's 97.4% accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
